import gymnasium as gym
import numpy as np
import matplotlib.pyplot as plt
from collections import deque

 # Environment
env = gym.make(
    "FrozenLake-v1",
    map_name="4x4",
    is_slippery=True
)

n_states = env.observation_space.n
n_actions = env.action_space.n

# -----------------------------
# Q-learning parameters
# -----------------------------
alpha =            # learning rate
gamma =            # discount factor

epsilon =          # initial exploration rate
epsilon_min =      # minimum exploration rate
epsilon_decay =    # exploration decay factor

num_episodes =     
max_steps =        

# -----------------------------
# Q-table
# -----------------------------
Q = np.zeros((n_states, n_actions))

# -----------------------------
# Tracking performance
# -----------------------------
success_window = deque(maxlen=100)
success_rates = []

# -----------------------------
# Training loop
# -----------------------------
for episode in range(num_episodes):
    state, _ = env.reset()
    done = False
    success = 0

    for _ in range(max_steps):
        if np.random.rand() < epsilon:
            action = env.action_space.sample()
        else:
            action = np.argmax(Q[state])

        next_state, reward, terminated, truncated, _ = env.step(action)
        done = terminated or truncated

        Q[state, action] += alpha * (
            reward + gamma * np.max(Q[next_state]) - Q[state, action]
        )

        state = next_state

        if done:
            success = reward
            break

    epsilon = max(epsilon_min, epsilon * epsilon_decay)

    success_window.append(success)
    success_rates.append(np.mean(success_window))

# -----------------------------
# Plot learning curve
# -----------------------------
plt.figure()
plt.plot(success_rates)
plt.xlabel("Episode")
plt.ylabel("Success Rate (last 100 episodes)")
plt.title("FrozenLake Q-Learning Performance")
plt.show()